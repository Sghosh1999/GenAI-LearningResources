{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d33cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f70062",
   "metadata": {},
   "source": [
    "#### Loading The OpenAPI Key from Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74bd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14be963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Teh Client Object\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ[\"OPENAI_API_kEY\"]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e73d67",
   "metadata": {},
   "source": [
    "Splitting Text into Chunks: The function utilizes the CharacterTextSplitter from Langchain to split the input text into smaller chunks. These chunks are separated by newline characters (\"\\n\") and are of a maximum size of 1000 characters (chunk_size=1000). Additionally, there is an overlap of 200 characters between consecutive chunks (chunk_overlap=200).\n",
    "\n",
    "Converting Text Chunks into Embeddings: After splitting the text into chunks, the function seems to convert each chunk into embeddings using OpenAIEmbeddings. This assumes that OpenAIEmbeddings is a class responsible for converting text into embeddings, possibly using a pre-trained model like GPT.\n",
    "\n",
    "Forming a Knowledge Base: Finally, the function seems to create a knowledge base from the embeddings generated from the text chunks. It's using FAISS to index and retrieve embeddings efficiently. The FAISS.from_texts method likely creates an index from the embeddings of the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaa8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Split the text into chunks using Langchain's CharacterTextSplitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Convert the chunks of text into embeddings to form a knowledge base (OpenAI Embedding)\n",
    "    #embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    #Huggingface Embedding (\"all-MiniLM-L6-v2\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
    "    \n",
    "    return knowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4fad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d358c24c2a8460e8bcb3618c81061b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sayantan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sayantan\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2b221e828a4e109b0b25aac656a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba42b8cda6b40088a81d05e5a448559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4e84d9f2234e66aced0c57a6328b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c5b014199d4279a77fd70c7eb6fedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c742010d13e24ce598970d95ce2e0045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5df49235d3e4c49a835fb1c42348275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32320f7d53294d3592ab88f1b1270732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ae1bc60a6e444794a94446e91cfe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4b4045cc584b08b1d913a215c078eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186d22bb1102478f83bf1289c69ef0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_reader = PdfReader(\"amazon-rainforest-sample_doc.pdf\")\n",
    "# Text variable will store the pdf text\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "    \n",
    "# Create the knowledge base object\n",
    "knowledgeBase = process_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72852761",
   "metadata": {},
   "source": [
    "### Based on a Query -> We are deriving the similarity score using Huggingface Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a835de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the Oxygen perchentage of Amazon?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e51f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Amazon is essential to its local inhabitants and also to life all over the planet. \\xa0\\n \\xa0\\n ‚óè Amazon trees account for about a quarter of the carbon dioxide absorbed by the earth each year, \\xa0\\n making it\\u200b  \\u200b a \\u200b major plane tary carbon sink \\u200b ‚Äî the Amazon trees account for a quarter of carbon dioxide \\xa0\\n absorbed by the land annually. This, however, is changing fast as the Amazon passes its saturation \\xa0\\n point for carbon. \\xa0 \\xa0\\n ‚óè The Amazon‚Äôs forests produce massive amounts of oxygen; estimates say that the region generates \\xa0\\n more than 20% of the earth‚Äôs oxygen\\u200b . \\xa0 \\xa0\\n ‚óè The region‚Äôs forests\\u200b  \\u200b pump 20 billion tons of water into the atmosphere every day\\u200b . \\u200b In Brazil, 70% \\xa0\\n of water evaporation responsible for precipitation comes from the Amazon. \\xa0\\n ‚óè The Amazon plays \\u200b a crit ical role in regulating the global climate\\u200b , through its absorption of carbon \\xa0\\n and emission of water. \\xa0 \\xa0\\n \\xa0\\n \\xa0\\n What are the biggest threats to the Amazon?'\n",
      "______________________________\n",
      "page_content='The Amazon Rainforest \\xa0\\n \\xa0\\n The Amazon rainforest is the \\u200b largest remaining tropical rainforest in the world\\u200b , blanketing the Earth‚Äôs \\xa0\\n surface in approximately\\u200b  \\u200b three billion trees\\u200b . Spanning nine countries in South America, the Amazon is an \\xa0\\n expansive and incredibly diverse biome‚Äî almost twenty-five times the size of the United Kingdom. Through the \\xa0\\n region snakes the Amazon River, flowing for more than 4,100 miles. \\xa0 \\xa0\\n \\xa0\\n ‚óè One fifth of world‚Äôs flowing water runs through the Amazon. \\xa0\\n ‚óè About 20% of the planet‚Äôs oxygen is produced in the Amazon. \\xa0\\n \\xa0\\n Biodiversity in the Amazon \\xa0\\n \\xa0\\n As of 2005, the Amazon is home to at least \\u200b 10% of the entire planet‚Äôs known species\\u200b , including, at least: \\xa0\\n \\xa0\\n ‚óè 437 mammal species \\xa0 \\xa0\\n ‚óè 1,300 bird species \\xa0\\n ‚óè 378 reptile species \\xa0\\n ‚óè 400 amphibian species \\xa0 \\xa0\\n ‚óè 3,000 fish species \\xa0 \\xa0\\n ‚óè 40,000 to 53,000 tree species'\n"
     ]
    }
   ],
   "source": [
    "docs = knowledgeBase.similarity_search(query)\n",
    "\n",
    "# Check for first two results\n",
    "print(docs[0])\n",
    "print(\"___\"*10)\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bedf94e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sayantan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d4eff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe9c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sayantan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 954\n",
      "\tPrompt Tokens: 938\n",
      "\tCompletion Tokens: 16\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000493\n"
     ]
    }
   ],
   "source": [
    " with get_openai_callback() as cost:\n",
    "    response = chain.run(input_documents=docs, question=query)\n",
    "    print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef09a4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Amazon rainforest produces more than 20% of the Earth's oxygen.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961af1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
